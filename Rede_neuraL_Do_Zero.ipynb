{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPTJmFscwMU7HH3x6jLg2E+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JeanCarlosBarbosa88/JeanCarlosBarbosa88/blob/main/Rede_neuraL_Do_Zero.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf # Import tensorflow\n",
        "from time import time\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn, optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ],
      "metadata": {
        "id": "dvxk-FNucy3l"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.ToTensor()\n",
        "trainset = datasets.MNIST('./MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "valset = datasets.MNIST('./MNIST_data/', download=True, train=False, transform=transform)\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "wYy9MKCxevi6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f44ed0e-a7e7-4577-b540-d5213d261795"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 54.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.86MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 14.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 3.11MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST_data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(trainloader)\n",
        "images, etiquetas = next(dataiter)  # Change dataiter.next() to next(dataiter)\n",
        "plt.imshow(images[0].numpy().squeeze(), cmap='gray_r')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "pC9do5mmf9pC",
        "outputId": "1016196b-8ce4-4dbe-c155-9c97dfb32d7a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7e743e0bdcc0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (images[0].shape)#para verificar as dimensão do tensor de cada imagem\n",
        "print (etiquetas[0].shape)#para verificar as dimensões do tensor de cada etiqueta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CarVS2dWiT1B",
        "outputId": "012b35fd-1756-4cb2-ee55-2c495cd0b2f4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28])\n",
            "torch.Size([])\n"
          ]
        }
      ]
    },
    {
      "source": [
        "class Modelo(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Modelo, self).__init__()# camada de entrada, 784 neurônios que se ligam a 128\n",
        "        self.linear1 = nn.Linear(28*28, 128)# camada interna 1, 128 neurônios que se ligam a 64\n",
        "        self.linear2 = nn.Linear(128, 64)# camada interna 2, 64 neurônios que se ligam a 10\n",
        "        self.linear3 = nn.Linear(64, 10)#camada interna 2, 64 neurônios que se ligam a 10\n",
        "        #para camada de saida não e necessário definir nada pois só precisamos pegar o output da camada interna 2\n",
        "\n",
        "    def forward(self, x): # Ensure this line is indented at the same level as __init__\n",
        "        x = F.relu(self.linear1(x))# função de ativiaçãoda camada de entrada para camada interna 1\n",
        "        x = F.relu(self.linear2(x))# função de ativiaçãoda camada de entrada para camada interna 2\n",
        "        x = self.linear3(x)#função de ativação da camada interna 2 para camada de saida, nesse caso f(x)=x\n",
        "        return F.log_softmax(x, dim=1)#dados utilizados para calcular a perda"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "HBCQj5HomMIT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def treino(modelo, trainloader, device):\n",
        "    otimizador = optim.SGD(modelo.parameters(), lr=0.01, momentum=0.5)#otimizador\n",
        "    inicio = time()\n",
        "    criterio = nn.NLLLoss()#criterio de perda\n",
        "    EPOCHS = 10\n",
        "    modelo.train()\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        perda_acumulada = 0.0\n",
        "        for images, etiquetas in trainloader:\n",
        "\n",
        "            images = images.view(images.shape[0], -1)\n",
        "            otimizador.zero_grad()\n",
        "            output = modelo(images.to(device))\n",
        "            perda_instantanea = criterio(output, etiquetas.to(device))\n",
        "            perda_instantanea.backward()\n",
        "            otimizador.step()\n",
        "            perda_acumulada += perda_instantanea.item()\n",
        "\n",
        "        else:\n",
        "            print(\"Treino: Epoch {} - Perda Computada (média): {}\".format(epoch+1, perda_acumulada/len(trainloader)))\n",
        "            print(\"\\n Tempo de treino (em minutos) = \", (time()-inicio)/60)\n"
      ],
      "metadata": {
        "id": "03uBh_WMmhF1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validacao(modelo, valloader, device):\n",
        "  conta_corretas, conta_todas = 0, 0\n",
        "  for images, etiquetas in valloader:\n",
        "      for i in range(len(etiquetas)):\n",
        "        img = images[i].view(1, 784)\n",
        "        # desativar o autoarmazenamento\n",
        "        with torch.no_grad():\n",
        "            logps = modelo(img.to(device))\n",
        "        ps = torch.exp(logps)\n",
        "        probab = list(ps.cpu().numpy()[0])\n",
        "        etiqueta_pred = probab.index(max(probab))\n",
        "        etiqueta_certa = etiquetas.numpy()[i]\n",
        "        if(etiqueta_certa == etiqueta_pred):\n",
        "            conta_corretas += 1\n",
        "            conta_todas += 1\n",
        "  print(\"Total de imagens testadas= {}/{}\".format(conta_corretas, conta_todas))\n",
        "  print(\"\\nPrecisão do modelo = {}%\".format(100 * conta_corretas / conta_todas))"
      ],
      "metadata": {
        "id": "d0o2sS_4opiz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = Modelo()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "modelo.to(device)\n",
        "treino(modelo, trainloader, device)\n",
        "validacao(modelo, valloader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yacP3wIKqSO2",
        "outputId": "b0468c15-0bad-4f75-d9e0-0713749c0836"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treino: Epoch 1 - Perda Computada (média): 1.1449764407456302\n",
            "\n",
            " Tempo de treino (em minutos) =  0.18404698769251507\n",
            "Treino: Epoch 2 - Perda Computada (média): 0.3793458106405318\n",
            "\n",
            " Tempo de treino (em minutos) =  0.35003326336542767\n",
            "Treino: Epoch 3 - Perda Computada (média): 0.3099146953730314\n",
            "\n",
            " Tempo de treino (em minutos) =  0.5078118125597636\n",
            "Treino: Epoch 4 - Perda Computada (média): 0.268697079096331\n",
            "\n",
            " Tempo de treino (em minutos) =  0.659027083714803\n",
            "Treino: Epoch 5 - Perda Computada (média): 0.23743203248995454\n",
            "\n",
            " Tempo de treino (em minutos) =  0.8206746737162273\n",
            "Treino: Epoch 6 - Perda Computada (média): 0.21230210681189735\n",
            "\n",
            " Tempo de treino (em minutos) =  0.9820211211840312\n",
            "Treino: Epoch 7 - Perda Computada (média): 0.19163423439841282\n",
            "\n",
            " Tempo de treino (em minutos) =  1.130583143234253\n",
            "Treino: Epoch 8 - Perda Computada (média): 0.17374670347456994\n",
            "\n",
            " Tempo de treino (em minutos) =  1.2891189376513164\n",
            "Treino: Epoch 9 - Perda Computada (média): 0.15881554228164305\n",
            "\n",
            " Tempo de treino (em minutos) =  1.4675973614056905\n",
            "Treino: Epoch 10 - Perda Computada (média): 0.14580295967267776\n",
            "\n",
            " Tempo de treino (em minutos) =  1.6316654562950135\n",
            "Total de imagens testadas= 9569/9569\n",
            "\n",
            "Precisão do modelo = 100.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nova seção"
      ],
      "metadata": {
        "id": "ro3P0xXqbuX2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_E-gyR4JOqll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "\n",
        "# Definindo a transformação (pré-processamento dos dados)\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# Carregando os dados de treino e validação do MNIST\n",
        "trainset = datasets.MNIST('./MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "valset = datasets.MNIST('./MNIST_data/', download=True, train=False, transform=transform)\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Visualizando uma imagem de exemplo\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)\n",
        "plt.imshow(images[0].numpy().squeeze(), cmap='gray_r')\n",
        "plt.show()\n",
        "\n",
        "print(f'Tamanho da imagem: {images[0].shape}')  # Verificando as dimensões\n",
        "\n",
        "# Definindo o Modelo da Rede Neural (modelo simples de 3 camadas)\n",
        "class Modelo(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Modelo, self).__init__()\n",
        "        self.linear1 = nn.Linear(28*28, 128)  # Primeira camada\n",
        "        self.linear2 = nn.Linear(128, 64)     # Segunda camada\n",
        "        self.linear3 = nn.Linear(64, 10)      # Camada de saída (10 classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)  # Achata as imagens para 1D\n",
        "        x = F.relu(self.linear1(x))  # Função ReLU após a primeira camada\n",
        "        x = F.relu(self.linear2(x))  # Função ReLU após a segunda camada\n",
        "        x = self.linear3(x)  # Saída final sem ativação, pois vamos usar log_softmax\n",
        "        return F.log_softmax(x, dim=1)  # log_softmax para calcular a probabilidade\n",
        "\n",
        "# Função de treinamento\n",
        "def treino(modelo, trainloader, device):\n",
        "    otimizador = optim.SGD(modelo.parameters(), lr=0.01, momentum=0.5)\n",
        "    criterio = nn.NLLLoss()  # Função de perda de log-likelihood\n",
        "    EPOCHS = 10\n",
        "    modelo.train()\n",
        "\n",
        "    inicio = time()\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        perda_acumulada = 0.0\n",
        "        for images, labels in trainloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            otimizador.zero_grad()\n",
        "            output = modelo(images)\n",
        "            perda = criterio(output, labels)\n",
        "            perda.backward()\n",
        "            otimizador.step()\n",
        "            perda_acumulada += perda.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}, Perda média: {perda_acumulada/len(trainloader):.4f}\")\n",
        "\n",
        "    print(f'Tempo de treino: {(time()-inicio)/60:.2f} minutos')\n",
        "\n",
        "# Função de validação\n",
        "def validacao(modelo, valloader, device):\n",
        "    modelo.eval()  # Coloca o modelo em modo de avaliação\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():  # Desabilita o cálculo de gradientes para a avaliação\n",
        "        for images, labels in valloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            output = modelo(images)\n",
        "            _, predicted = torch.max(output, 1)  # Obtém a classe com maior probabilidade\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f'Precisão no conjunto de validação: {100 * correct / total:.2f}%')\n",
        "\n",
        "#Função para carregar e processar imagem\n",
        "def carregar_imagem (imagem_path):\n",
        "  img = Image.open(imagem_path).convert('L')#converte para escala de cinza\n",
        "  transform = transforms.Compose([\n",
        "      transforms.Resize((28, 28)),   #redimensiona para 28x28 pixels\n",
        "      transforms.ToTensor(),       #converte para tensor\n",
        "      transforms.Normalize((0.5,), (0.5,))  #normalizção do MNIST\n",
        "  ])\n",
        "  img_tensor = transform(img)\n",
        "  img_tensor = img_tensor.unsqueeze(0)\n",
        "  return img_tensor\n",
        "\n",
        "#função para revisão\n",
        "def prever_imagem(modelo, imagem_tensor, device):\n",
        "  imagem_tensor = carregar_imagem(imagem_path)\n",
        "  imagem_tensor = imagem_tensor.to(device)\n",
        "\n",
        "  modelo.eval() # coloca em avaliação o modelo\n",
        "  with torch.no_grad():\n",
        "    output = modelo(imagem_tensor)\n",
        "    _, predicted = torch.max(output, 1)\n",
        "    print(f'A imagem é prevista como: {predicted.item()}')\n",
        "\n",
        "    #exibição da imagem\n",
        "    img = image.open(imagem_path).convert('L')\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.title(f'Predição: {predicted.item()}')\n",
        "    plt.show()\n",
        "\n",
        "modelo = Modelo\n",
        "\n",
        "# Definindo o dispositivo (GPU ou CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "modelo = Modelo().to(device)\n",
        "\n",
        "# Chamando as funções de treinamento e validação\n",
        "treino(modelo, trainloader, device)\n",
        "validacao(modelo, valloader, device)\n",
        "\n",
        "#testar nova imagem\n",
        "imagem_path = 'jean.jpg'\n",
        "prever_imagem(modelo, imagem_path, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "9OZCqUlZGmUH",
        "outputId": "6d61c603-0920-47a4-e884-c338b9d2604f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho da imagem: torch.Size([1, 28, 28])\n",
            "Epoch 1, Perda média: 0.7230\n",
            "Epoch 2, Perda média: 0.3139\n",
            "Epoch 3, Perda média: 0.2616\n",
            "Epoch 4, Perda média: 0.2223\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n"
      ],
      "metadata": {
        "id": "R5bBprTSIA7P"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Para 3 canais (RGB)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfSQBU_UcQV4",
        "outputId": "99c92375-6c3b-4fa4-a41d-2fedf5a970dc"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN_Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN_Model, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc1 = nn.Linear(7*7*64, 128)  # Aqui o número depende da imagem após convolução\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = x.view(-1, 7*7*64)  # Flattening\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)\n"
      ],
      "metadata": {
        "id": "XZzBwHxXcSYp"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = datasets.MNIST('./MNIST_data/', download=True, train=True, transform=transform)\n"
      ],
      "metadata": {
        "id": "g5TPvIlOcUg6"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujpq3UYXcXQZ",
        "outputId": "30cb81d7-bb07-4163-fa9f-46d49ef758f2"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:02<00:00, 58.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "otimizador = optim.Adam(modelo.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "ISXDd3JOcacD"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterio = nn.CrossEntropyLoss()  # Para problemas com múltiplas classes"
      ],
      "metadata": {
        "id": "F3aWRcVFccii"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10  # Altere o número conforme necessário"
      ],
      "metadata": {
        "id": "GO-wUbzncklD"
      },
      "execution_count": 74,
      "outputs": []
    }
  ]
}